{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2caf9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bhupendra/anaconda3/envs/gpvae1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/bhupendra/anaconda3/envs/gpvae1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/bhupendra/anaconda3/envs/gpvae1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/bhupendra/anaconda3/envs/gpvae1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/bhupendra/anaconda3/envs/gpvae1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/bhupendra/anaconda3/envs/gpvae1/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import math_ops as tfmath_ops\n",
    "# from utils import Make_Video_batch, make_checkpoint_folder\n",
    "# from utils import build_video_batch_graph, plot_latents, MSE_rotation\n",
    "# from utils import pandas_res_saver\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "# from utils_circles_grid import Make_circles, Make_squares, plot_circle\n",
    "# from utils_circles_grid import plot_heatmap, plot_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef90e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_path_batch(\n",
    "    batch=40,\n",
    "    tmax=30,\n",
    "    lt=5,\n",
    "    seed=None\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Samples x(t), y(t) from a GP\n",
    "    args:\n",
    "        batch: number of samples\n",
    "        tmax: length of samples\n",
    "        lt: GP length scale\n",
    "    returns:\n",
    "        traj: nparray (batch, tmax, 2)\n",
    "    \"\"\"\n",
    "\n",
    "    ilt = -0.5/(lt*lt)\n",
    "    T = np.arange(tmax)\n",
    "\n",
    "    Sigma = np.exp( ilt * (T.reshape(-1,1) - T.reshape(1,-1))**2)\n",
    "#     print(Sigma.shape)\n",
    "    Mu = np.zeros(tmax)\n",
    "#     print(Mu.shape)\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    traj = np.random.multivariate_normal(Mu, Sigma, (batch, 3))\n",
    "    traj = np.transpose(traj, (0,2,1))\n",
    "\n",
    "    return traj\n",
    "\n",
    "def Make_Video_batch(tmax=50,\n",
    "    px=10,\n",
    "    py=10,\n",
    "    pz=10,\n",
    "    lt=5,\n",
    "    batch=40,\n",
    "    seed=1,\n",
    "    r=2\n",
    "    ):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        tmax: number of frames to generate\n",
    "        px: horizontal resolution\n",
    "        py: vertical resolution\n",
    "        lt: length scale\n",
    "        batch: number of videos\n",
    "        seed: rng seed\n",
    "        r: radius of ball in pixels\n",
    "    \n",
    "    returns:\n",
    "        traj0: (batch, tmax, 2) numpy array\n",
    "        vid_batch: (batch, tmax, px, py) numpy array\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    traj0 = Make_path_batch(batch=batch, tmax=tmax, lt=lt)\n",
    "\n",
    "    traj = traj0.copy()\n",
    "\n",
    "    # convert trajectories to pixel dims\n",
    "    traj[:,:,0] = traj[:,:,0] * (px/5) + (0.5*px)\n",
    "    traj[:,:,1] = traj[:,:,1] * (py/5) + (0.5*py)\n",
    "    traj[:,:,2] = traj[:,:,2] * (py/5) + (0.5*py)\n",
    "\n",
    "    rr = r*r\n",
    "\n",
    "    def pixelate_frame(xy):\n",
    "        \"\"\"\n",
    "        takes a single x,y pixel point and converts to binary image\n",
    "        with ball centered at x,y.\n",
    "        \"\"\"\n",
    "        x = xy[0]\n",
    "        y = xy[1]\n",
    "\n",
    "        sq_x = (np.arange(px) - x)**2\n",
    "        sq_y = (np.arange(py) - y)**2\n",
    "\n",
    "        sq = sq_x.reshape(1,-1) + sq_y.reshape(-1,1)\n",
    "\n",
    "        image = 1*(sq < rr)\n",
    "\n",
    "        return image\n",
    "\n",
    "    \n",
    "    def pixelate_series(XY):\n",
    "        vid = map(pixelate_frame, XY)\n",
    "        vid = [v for v in vid]\n",
    "        return np.asarray(vid)\n",
    "\n",
    "\n",
    "    vid_batch = [pixelate_series(traj_i) for traj_i in traj]\n",
    "\n",
    "    vid_batch = np.asarray(vid_batch)\n",
    "\n",
    "    return traj0#, vid_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a579ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_cross_entropy(mu1, var1, mu2, var2):\n",
    "    \"\"\"\n",
    "    Computes the element-wise cross entropy\n",
    "    Given q(z) ~ N(z| mu1, var1)\n",
    "    returns E_q[ log N(z| mu2, var2) ]\n",
    "    args:\n",
    "        mu1:  mean of expectation (batch, tmax, 2) tf variable\n",
    "        var1: var  of expectation (batch, tmax, 2) tf variable\n",
    "        mu2:  mean of integrand (batch, tmax, 2) tf variable\n",
    "        var2: var of integrand (batch, tmax, 2) tf variable\n",
    "\n",
    "    returns:\n",
    "        cross_entropy: (batch, tmax, 2) tf variable\n",
    "    \"\"\"\n",
    "    term0 = 1.8378770664093453 # log(2*pi)\n",
    "    term1 = tf.log(var2)\n",
    "    term2 = (var1 + mu1**2 - 2*mu1*mu2 + mu2**2) / var2\n",
    "    cross_entropy = -0.5*( term0 + term1 + term2 )\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def gauss_entropy(var1):\n",
    "    \"\"\"\n",
    "    Computes the element-wise entropy\n",
    "    Given q(z) ~ N(z| mu1, var1)\n",
    "    returns E_q[ log N(z| mu1, var1) ] = -0.5 ( log(var1) + 1 + log(2*pi) )\n",
    "    args:\n",
    "        var1: var  of expectation (batch, tmax, 2) tf variable\n",
    "\n",
    "    returns:\n",
    "        cross_entropy: (batch, tmax, 2) tf variable\n",
    "    \"\"\"\n",
    "    term0 = tf.log(var1) + 2.8378770664093453 # 1 + log(2*pi)\n",
    "    cross_entropy = -0.5*( term0 )\n",
    "    return cross_entropy\n",
    "\n",
    "\n",
    "def build_MLP_inference_graph(vid_batch, layers=[500], tftype=tf.float32):\n",
    "    \"\"\"\n",
    "    Takes a placeholder for batches of videos to be fed in, returns \n",
    "    a mean and var of 2d latent space that are tf variables.\n",
    "\n",
    "    args:\n",
    "        vid_batch: tf placeholder (batch, tmax, width, height)\n",
    "        layers: list of widths of fully connected layers\n",
    "        tftype: data type to use in graph\n",
    "\n",
    "    returns:\n",
    "        means:  tf variable, (batch, tmax, 2) x,y points\n",
    "        vars:  tf variable, (batch, tmax, 2) x,y uncertainties\n",
    "    \"\"\"\n",
    "\n",
    "    batch, tmax, px, py = vid_batch.get_shape()\n",
    "\n",
    "    # first layer, flatten images to vectors\n",
    "    h0 = tf.reshape(vid_batch, (batch*tmax, px*py))\n",
    "\n",
    "    # loop over layers in given list\n",
    "    for l in layers:\n",
    "        i_dims = int(h0.get_shape()[-1])\n",
    "        W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "                stddev=1.0 / np.sqrt(float(i_dims))), name=\"encW\")\n",
    "        B = tf.Variable(tf.zeros([1, l]), name=\"encB\")\n",
    "        h0 = tf.matmul(h0, W) + B\n",
    "        h0 = tf.nn.tanh(h0)\n",
    "\n",
    "    # final layer just outputs x,y mean and log(var) of q network\n",
    "    i_dims = int(h0.get_shape()[-1])\n",
    "    W = tf.Variable(tf.truncated_normal([i_dims, 6],\n",
    "            stddev=1.0 / np.sqrt(float(i_dims))), name=\"encW\")\n",
    "    B = tf.Variable(tf.zeros([1, 6]), name=\"encB\")\n",
    "    h0 = tf.matmul(h0, W) + B\n",
    "\n",
    "    h0 = tf.reshape(h0, (batch, tmax, 6))\n",
    "\n",
    "    #First 2 mean Next 2 variance\n",
    "    q_means = h0[:, :, :3]\n",
    "    q_vars  = tf.exp(h0[:, :, 3:])\n",
    "\n",
    "    return q_means, q_vars\n",
    "\n",
    "def build_MLP_decoder_graph(latent_samples, px, py, layers=[500]):\n",
    "    \"\"\"\n",
    "    Constructs a TF graph that goes from latent points in 2D time series\n",
    "    to a bernoulli probabilty for each pixel in output video time series.\n",
    "    Args:\n",
    "        latent_samples: (batch, tmax, 2), tf variable\n",
    "        px: image width (int)\n",
    "        py: image height (int)\n",
    "        layers: list of num. of nodes (list of ints)\n",
    "\n",
    "    Returns:\n",
    "        pred_batch_vid_logits: (batch, tmax, px, py) tf variable\n",
    "    \"\"\"\n",
    "    batch, tmax, _ = latent_samples.get_shape()\n",
    "    # flatten all latents into one matrix (decoded in i.i.d fashion)\n",
    "    h0 = tf.reshape(latent_samples, (batch*tmax, 3))\n",
    "\n",
    "    # loop over layers in given list\n",
    "    for l in layers:\n",
    "        i_dims = int(h0.get_shape()[-1])\n",
    "        W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "                stddev=1.0 / np.sqrt(float(i_dims))), name=\"decW\")\n",
    "        B = tf.Variable(tf.zeros([1, l]), name=\"decB\")\n",
    "        h0 = tf.matmul(h0, W) + B\n",
    "        h0 = tf.nn.tanh(h0)\n",
    "\n",
    "    # final layer just outputs full video batch\n",
    "    l = px*py\n",
    "    i_dims = int(h0.get_shape()[-1])\n",
    "    W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "            stddev=1.0 / np.sqrt(float(i_dims))), name=\"decW\")\n",
    "    B = tf.Variable(tf.zeros([1, l]), name=\"decB\")\n",
    "    h0 = tf.matmul(h0, W) + B\n",
    "    pred_vid_batch_logits = tf.reshape(h0, (batch, tmax, px, py))\n",
    "    return pred_vid_batch_logits\n",
    "\n",
    "def build_1d_gp(X, Y, varY, X_test, lt=5):\n",
    "    \"\"\"\n",
    "    Takes input-output dataset and returns post mean, var, marginal lhood.\n",
    "    This is standard GP regression (in this application X is time, Y is \n",
    "    recognition network means with noise as recognition netowrk variance).\n",
    "\n",
    "    Args:\n",
    "        X: inputs tensor (batch, npoints)\n",
    "        Y: outputs tensor (batch, npoints)\n",
    "        varY: noise of outputs tensor (batch, npoints)\n",
    "        X_test: (batch, ns) input points to compute post mean + var\n",
    "\n",
    "    Returns:\n",
    "        p_m: (batch, ns) post mean at X_test\n",
    "        p_v: (batch, ns) post var at X_test\n",
    "        logZ: (batch) marginal lhood of each dataset in batch\n",
    "    \"\"\"\n",
    "\n",
    "    # Prepare all constants\n",
    "    batch, _ = X.get_shape()\n",
    "    n = tf.shape(X)[1]\n",
    "    _, ns = X_test.get_shape()\n",
    "\n",
    "    # inverse square length scale\n",
    "    ilt = tf.constant( -0.5*(1/(lt*lt)) )\n",
    "    \n",
    "    # lhood term 1/3\n",
    "    lhood_pi_term = tf.cast(n, dtype=tf.float32) * np.log(2*np.pi)\n",
    "    \n",
    "    # data cov matrix K = exp( -1/2 * (X-X)**2/l**2) + noise\n",
    "    K = tf.reshape(X, (batch, n, 1)) - tf.reshape(X, (batch, 1, n)) # (batch, n n)\n",
    "    K = tf.exp( (K**2) * ilt)  + tf.matrix_diag(varY) \n",
    "    chol_K = tf.linalg.cholesky(K) # (batch, n, n)\n",
    "\n",
    "    # lhood term 2/3\n",
    "    lhood_logdet_term = 2*tf.reduce_sum(tf.log(tf.matrix_diag_part(chol_K)), 1) # (batch)\n",
    "\n",
    "    # lhood term 3/3\n",
    "    Y = tf.reshape(Y, (batch, n, 1))\n",
    "    iKY = tf.cholesky_solve( chol_K, Y) # (batch, n, 1)\n",
    "    lh_quad_term = tf.matmul(tf.reshape(Y, (batch, 1, n)), iKY) # (batch, 1, 1)\n",
    "    lh_quad_term = tf.reshape(lh_quad_term, [batch])\n",
    "\n",
    "    # log P(Y|X) = -1/2 * ( n log(2 pi) + Y inv(K+noise) Y + log det(K+noise))\n",
    "    gp_lhood = -0.5*( lhood_pi_term + lh_quad_term + lhood_logdet_term )\n",
    "\n",
    "    # Compute posterior mean and variances\n",
    "    Ks = tf.reshape(X, (batch, n, 1)) - tf.reshape(X_test, (batch, 1, ns)) #broadcasts to (batch, n, ns)\n",
    "    Ks = tf.exp( (Ks**2) * ilt) # (batch, n, ns)\n",
    "    Ks_t = tf.transpose(Ks, (0, 2, 1)) # (batch, ns, n)\n",
    "\n",
    "    # posterior mean\n",
    "    p_m = tf.matmul(Ks_t, iKY)\n",
    "    p_m = tf.reshape(p_m, (batch, ns))\n",
    "\n",
    "    # posterior variance\n",
    "    iK_Ks = tf.cholesky_solve(chol_K, Ks) # (batch, n, ns)\n",
    "    Ks_iK_Ks = tf.reduce_sum(Ks * iK_Ks, axis=1) # (batch, ns)\n",
    "    p_v = 1 - Ks_iK_Ks # (batch, ns)\n",
    "    p_v = tf.reshape(p_v, (batch, ns))\n",
    "\n",
    "    return p_m, p_v, gp_lhood\n",
    "\n",
    "def build_sin_and_np_elbo_graphs(vid_batch, beta, lt=5, context_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Builds both standard (sin) eblo and neural process (np) elbo. \n",
    "    Returns pretty much everything!\n",
    "    Args:\n",
    "        vid_batch: tf variable (batch, tmax, px, py) binay arrays or images\n",
    "        beta: scalar, tf variable, annealing term for prior KL\n",
    "        lt: length scale of GP\n",
    "        context_ratio: float in [0,1], for np elbo, random target-context split ratio\n",
    "\n",
    "    Returns:\n",
    "        sin_elbo: \"standard\" elbo\n",
    "        sin_elbo_recon: recon struction term\n",
    "        sin_elbo_prior_kl: prior KL term\n",
    "        np_elbo: neural process elbo\n",
    "        np_elbo_recon: ...\n",
    "        np_prior_kl: ...\n",
    "        full_p_mu: approx posterior mean\n",
    "        full_p_var: approx post var\n",
    "        qnet_mu: recognition network mean\n",
    "        qnet_var: recog. net var\n",
    "        pred_vid: reconstructed video\n",
    "        globals(): aaaalll variables in local scope\n",
    "    \"\"\"\n",
    "\n",
    "    batch, tmax, px, py = [int(s) for s in vid_batch.get_shape()]\n",
    "\n",
    "    # Choose a random split of target-context for each batch\n",
    "    con_tf = tf.random.normal(shape=(),\n",
    "                              mean=context_ratio*float(tmax),\n",
    "                              stddev=np.sqrt(context_ratio*(1-context_ratio)*float(tmax)))\n",
    "    con_tf = tf.math.maximum(con_tf, 2)\n",
    "    con_tf = tf.math.minimum(con_tf, int(tmax)-2)\n",
    "    con_tf = tf.cast(tf.round(con_tf), tf.int32)\n",
    "\n",
    "    dt = vid_batch.dtype\n",
    "    \n",
    "    # recognition network terms\n",
    "    qnet_mu, qnet_var = build_MLP_inference_graph(vid_batch)\n",
    "\n",
    "    ##################################################################\n",
    "    ####################### CONTEXT LIKELIHOOD #######################\n",
    "    # make random indices\n",
    "    ran_ind = tf.range(tmax, dtype=tf.int32)\n",
    "    ran_ind = [tf.random.shuffle(ran_ind) for i in range(batch)] # (batch, tmax)\n",
    "    ran_ind = [tf.reshape(r_i, (1,tmax)) for r_i in ran_ind] # len batch list( (tmax), ..., (tmax) )\n",
    "    ran_ind = tf.concat(ran_ind, 0) # ()\n",
    "\n",
    "    con_ind = ran_ind[:, :con_tf]\n",
    "    tar_ind = ran_ind[:, con_tf:]\n",
    "\n",
    "    T = tf.range(tmax, dtype=dt)\n",
    "    batch_T = tf.concat([tf.reshape(T, (1,tmax)) for i in range(batch)], 0) # (batch, tmax)\n",
    "\n",
    "    # time stamps of context points\n",
    "    con_T = [tf.gather(T, con_ind[i,:]) for i in range(batch)]\n",
    "    con_T = [tf.reshape(ct, (1,con_tf)) for ct in con_T]\n",
    "    con_T = tf.concat(con_T, 0)\n",
    "\n",
    "    # encoded means of contet points\n",
    "    con_lm = [tf.gather(qnet_mu[i,:,:], con_ind[i,:], axis=0) for i in range(batch)]\n",
    "    con_lm = [tf.reshape(cm, (1,con_tf,2)) for cm in con_lm]\n",
    "    con_lm = tf.concat(con_lm, 0)\n",
    "\n",
    "    # encoded variances of context points\n",
    "    con_lv = [tf.gather(qnet_var[i,:,:], con_ind[i,:], axis=0) for i in range(batch)]\n",
    "    con_lv = [tf.reshape(cv, (1,con_tf,2)) for cv in con_lv]\n",
    "    con_lv = tf.concat(con_lv, 0)\n",
    "\n",
    "    # conext Lhoods\n",
    "    _,_, con_lhoodx = build_1d_gp(con_T, con_lm[:,:,0], con_lv[:,:,0], batch_T)\n",
    "    _,_, con_lhoody = build_1d_gp(con_T, con_lm[:,:,1], con_lv[:,:,1], batch_T)\n",
    "    con_lhood = con_lhoodx + con_lhoody\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    #################### PriorKL 1/3: FULL APPROX POST AND LIKELIHOOD ##################\n",
    "\n",
    "    # posterior and lhood for full dataset\n",
    "    p_mx, p_vx, full_lhoodx = build_1d_gp(batch_T, qnet_mu[:,:,0], qnet_var[:,:,0], batch_T)\n",
    "    p_my, p_vy, full_lhoody = build_1d_gp(batch_T, qnet_mu[:,:,1], qnet_var[:,:,1], batch_T)\n",
    "\n",
    "    full_p_mu = tf.stack([p_mx, p_my], axis=2)\n",
    "    full_p_var = tf.stack([p_vx, p_vy], axis=2)\n",
    "\n",
    "    full_lhood = full_lhoodx + full_lhoody\n",
    "\n",
    "    ####################################################################################\n",
    "    ########################### PriorKL 2/3: CROSS ENTROPY TERMS #######################\n",
    "\n",
    "    # cross entropy term\n",
    "    sin_elbo_ce = gauss_cross_entropy(full_p_mu, full_p_var, qnet_mu, qnet_var) #(batch, tmax, 2)\n",
    "    sin_elbo_ce = tf.reduce_sum(sin_elbo_ce, 2) # (batch, tmax)\n",
    "\n",
    "\n",
    "    np_elbo_ce = [tf.gather(sin_elbo_ce[i,:], tar_ind[i,:]) for i in range(batch)] # (batch, con_tf)\n",
    "    np_elbo_ce = [tf.reduce_sum(np_i) for np_i in np_elbo_ce] # list of scalars, len=batch\n",
    "\n",
    "    np_elbo_ce = tf.stack(np_elbo_ce) # (batch)\n",
    "    sin_elbo_ce = tf.reduce_sum(sin_elbo_ce, 1) # (batch)\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    ################################ Prior KL 3/3 ######################################\n",
    "\n",
    "    sin_elbo_prior_kl = full_lhood - sin_elbo_ce\n",
    "    np_prior_kl       = full_lhood - np_elbo_ce - con_lhood\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    ########################### RECONSTRUCTION TERMS ###################################\n",
    "\n",
    "    epsilon = tf.random.normal(shape=(batch, tmax, 2))\n",
    "    latent_samples = full_p_mu + epsilon * tf.sqrt(full_p_var)\n",
    "    pred_vid_batch_logits = build_MLP_decoder_graph(latent_samples, px, py)\n",
    "    pred_vid = tf.nn.sigmoid(pred_vid_batch_logits)\n",
    "    recon_err = tf.nn.sigmoid_cross_entropy_with_logits(labels=vid_batch, \n",
    "                                                        logits=pred_vid_batch_logits)\n",
    "    sin_elbo_recon = tf.reduce_sum(-recon_err, (2,3)) # (batch, tmax)\n",
    "\n",
    "    np_elbo_recon = [tf.gather(sin_elbo_recon[i,:], tar_ind[i,:]) for i in range(batch)] # (batch, con_tf)\n",
    "    np_elbo_recon = [tf.reduce_sum(np_i) for np_i in np_elbo_recon]\n",
    "\n",
    "    # finally the reconstruction error for each objective!\n",
    "    np_elbo_recon = tf.stack(np_elbo_recon)  # (batch)\n",
    "    sin_elbo_recon = tf.reduce_sum(sin_elbo_recon, 1) # (batch)\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################################################\n",
    "    ####################### PUT IT ALL TOGETHER  ########################################\n",
    "\n",
    "    sin_elbo = sin_elbo_recon + beta * sin_elbo_prior_kl\n",
    "    \n",
    "    np_elbo  = np_elbo_recon + beta * np_prior_kl\n",
    "\n",
    "    return sin_elbo, sin_elbo_recon, sin_elbo_prior_kl, \\\n",
    "           np_elbo,   np_elbo_recon,       np_prior_kl, \\\n",
    "           full_p_mu, full_p_var, \\\n",
    "           qnet_mu, qnet_var, pred_vid, globals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6f807f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"concat_356:0\", shape=(1, 50, 10, 10, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "def build_video_batch_graph(tmax=50,\n",
    "    px=10,\n",
    "    py=10,\n",
    "    pz=10,\n",
    "    lt=5,\n",
    "    batch=1,\n",
    "    seed=1,\n",
    "    r=2,\n",
    "    dtype=tf.float32):\n",
    "\n",
    "#     assert px==py, \"video batch graph assumes square frames\"\n",
    "\n",
    "    rr = r*r*r\n",
    "\n",
    "    ilt = tf.constant(-0.5/(lt**2), dtype=dtype)\n",
    "\n",
    "    K = tf.range(tmax, dtype=dtype)\n",
    "    K = (tf.reshape(K, (tmax, 1)) - tf.reshape(K, (1, tmax)))**2\n",
    "#     print(K.shape)\n",
    "\n",
    "    # print((K*ilt).get_shape())\n",
    "    # sys.exit()\n",
    "\n",
    "\n",
    "    K = tf.exp(K*ilt) + 0.00001*tf.eye(tmax, dtype=dtype)\n",
    "    chol_K = tf.Variable(tf.linalg.cholesky(K), trainable=False)\n",
    "\n",
    "#     ran_Z = tf.random.normal((tmax, 2*batch))\n",
    "    ran_Z = tf.random.normal((tmax, 3*batch))\n",
    "\n",
    "    paths = tf.matmul(chol_K, ran_Z)\n",
    "#     paths = tf.reshape(paths, (tmax, batch, 2))\n",
    "    paths = tf.reshape(paths, (tmax, batch, 3))\n",
    "    paths = tf.transpose(paths, (1,0,2))\n",
    "#     print(paths.shape)\n",
    "\n",
    "    # assumes px = py\n",
    "    paths = paths*0.2*px + 0.5*px + 0.8*pz\n",
    "    # paths[:,:,0] = paths[:,:,0]*0.2*px + 0.5*px\n",
    "    # paths[:,:,1] = paths[:,:,1]*0.2*py + 0.5*py\n",
    "\n",
    "    vid_batch = []\n",
    "\n",
    "    tf_px = tf.range(px, dtype=dtype)\n",
    "    tf_py = tf.range(py, dtype=dtype)\n",
    "    tf_pz = tf.range(pz, dtype=dtype)\n",
    "    for b in range(batch):\n",
    "        frames_tmax = []\n",
    "        for t in range(tmax):\n",
    "            lx = tf.reshape((tf_px - paths[b,t,0])**2, (px, 1, 1))\n",
    "            ly = tf.reshape((tf_py - paths[b,t,1])**2, (1, py, 1))\n",
    "            lz = tf.reshape((tf_py - paths[b,t,2])**2, (1,1, pz))\n",
    "#             print(lx.shape, ly.shape)\n",
    "            frame = lx + ly +lz< rr\n",
    "#             print(frame.shape)\n",
    "            frames_tmax.append(tf.reshape(frame, (1,1,px,py, pz)))\n",
    "        vid_batch.append(tf.concat(frames_tmax, 1))\n",
    "        \n",
    "\n",
    "    vid_batch = [tfmath_ops.cast(vid, dtype=dtype) for vid in vid_batch]\n",
    "    vid_batch = tf.concat(vid_batch, 0)\n",
    "\n",
    "    return vid_batch\n",
    "\n",
    "x = build_video_batch_graph()\n",
    "print(x)\n",
    "# tf.print(x[0][0], output_stream=sys.stdout)\n",
    "# tensor = tf.range(10)\n",
    "# tf.print(tensor, output_stream=sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44d8fc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_MLP_inference_graph(vid_batch, layers=[500], tftype=tf.float32):\n",
    "    \"\"\"\n",
    "    Takes a placeholder for batches of videos to be fed in, returns \n",
    "    a mean and var of 2d latent space that are tf variables.\n",
    "\n",
    "    args:\n",
    "        vid_batch: tf placeholder (batch, tmax, width, height)\n",
    "        layers: list of widths of fully connected layers\n",
    "        tftype: data type to use in graph\n",
    "\n",
    "    returns:\n",
    "        means:  tf variable, (batch, tmax, 2) x,y points\n",
    "        vars:  tf variable, (batch, tmax, 2) x,y uncertainties\n",
    "    \"\"\"\n",
    "\n",
    "    batch, tmax, px, py ,pz = vid_batch.get_shape()\n",
    "\n",
    "    # first layer, flatten images to vectors\n",
    "    h0 = tf.reshape(vid_batch, (batch*tmax, px*py*pz))\n",
    "\n",
    "    # loop over layers in given list\n",
    "    for l in layers:\n",
    "        i_dims = int(h0.get_shape()[-1])\n",
    "        W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "                stddev=1.0 / np.sqrt(float(i_dims))), name=\"encW\")\n",
    "        B = tf.Variable(tf.zeros([1, l]), name=\"encB\")\n",
    "        h0 = tf.matmul(h0, W) + B\n",
    "        h0 = tf.nn.tanh(h0)\n",
    "\n",
    "    # final layer just outputs x,y mean and log(var) of q network\n",
    "    i_dims = int(h0.get_shape()[-1])\n",
    "    W = tf.Variable(tf.truncated_normal([i_dims, 6],\n",
    "            stddev=1.0 / np.sqrt(float(i_dims))), name=\"encW\")\n",
    "    B = tf.Variable(tf.zeros([1, 6]), name=\"encB\")\n",
    "    h0 = tf.matmul(h0, W) + B\n",
    "\n",
    "    h0 = tf.reshape(h0, (batch, tmax, 6))\n",
    "\n",
    "    q_means = h0[:, :, :3]\n",
    "    q_vars  = tf.exp(h0[:, :, 3:])\n",
    "\n",
    "    return q_means, q_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e4b59302",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_MLP_decoder_graph(latent_samples, px, py,pz, layers=[500]):\n",
    "    \"\"\"\n",
    "    Constructs a TF graph that goes from latent points in 2D time series\n",
    "    to a bernoulli probabilty for each pixel in output video time series.\n",
    "    Args:\n",
    "        latent_samples: (batch, tmax, 2), tf variable\n",
    "        px: image width (int)\n",
    "        py: image height (int)\n",
    "        layers: list of num. of nodes (list of ints)\n",
    "\n",
    "    Returns:\n",
    "        pred_batch_vid_logits: (batch, tmax, px, py) tf variable\n",
    "    \"\"\"\n",
    "\n",
    "    batch, tmax, _ = latent_samples.get_shape()\n",
    "\n",
    "    # flatten all latents into one matrix (decoded in i.i.d fashion)\n",
    "#     h0 = tf.reshape(latent_samples, (batch*tmax, 2))\n",
    "    h0 = tf.reshape(latent_samples, (batch*tmax, 3))\n",
    "\n",
    "    # loop over layers in given list\n",
    "    for l in layers:\n",
    "        i_dims = int(h0.get_shape()[-1])\n",
    "        W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "                stddev=1.0 / np.sqrt(float(i_dims))), name=\"decW\")\n",
    "        B = tf.Variable(tf.zeros([1, l]), name=\"decB\")\n",
    "        h0 = tf.matmul(h0, W) + B\n",
    "        h0 = tf.nn.tanh(h0)\n",
    "\n",
    "    # final layer just outputs full video batch\n",
    "    l = px*py*pz\n",
    "    i_dims = int(h0.get_shape()[-1])\n",
    "    W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "            stddev=1.0 / np.sqrt(float(i_dims))), name=\"decW\")\n",
    "    B = tf.Variable(tf.zeros([1, l]), name=\"decB\")\n",
    "    h0 = tf.matmul(h0, W) + B\n",
    "\n",
    "    pred_vid_batch_logits = tf.reshape(h0, (batch, tmax, px, py, pz))\n",
    "\n",
    "    return pred_vid_batch_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "01b1924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sin_and_np_elbo_graphs(vid_batch, beta, lt=5, context_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Builds both standard (sin) eblo and neural process (np) elbo. \n",
    "    Returns pretty much everything!\n",
    "    Args:\n",
    "        vid_batch: tf variable (batch, tmax, px, py) binay arrays or images\n",
    "        beta: scalar, tf variable, annealing term for prior KL\n",
    "        lt: length scale of GP\n",
    "        context_ratio: float in [0,1], for np elbo, random target-context split ratio\n",
    "\n",
    "    Returns:\n",
    "        sin_elbo: \"standard\" elbo\n",
    "        sin_elbo_recon: recon struction term\n",
    "        sin_elbo_prior_kl: prior KL term\n",
    "        np_elbo: neural process elbo\n",
    "        np_elbo_recon: ...\n",
    "        np_prior_kl: ...\n",
    "        full_p_mu: approx posterior mean\n",
    "        full_p_var: approx post var\n",
    "        qnet_mu: recognition network mean\n",
    "        qnet_var: recog. net var\n",
    "        pred_vid: reconstructed video\n",
    "        globals(): aaaalll variables in local scope\n",
    "    \"\"\"\n",
    "    print(\"BHU0\", vid_batch.get_shape())\n",
    "    batch, tmax, px, py, pz= [int(s) for s in vid_batch.get_shape()]\n",
    "\n",
    "    # Choose a random split of target-context for each batch\n",
    "    con_tf = tf.random.normal(shape=(),\n",
    "                              mean=context_ratio*float(tmax),\n",
    "                              stddev=np.sqrt(context_ratio*(1-context_ratio)*float(tmax)))\n",
    "    con_tf = tf.math.maximum(con_tf, 2)\n",
    "    con_tf = tf.math.minimum(con_tf, int(tmax)-2)\n",
    "    con_tf = tf.cast(tf.round(con_tf), tf.int32)\n",
    "\n",
    "    dt = vid_batch.dtype\n",
    "    \n",
    "    # recognition network terms\n",
    "    qnet_mu, qnet_var = build_MLP_inference_graph(vid_batch)\n",
    "\n",
    "    ##################################################################\n",
    "    ####################### CONTEXT LIKELIHOOD #######################\n",
    "    # make random indices\n",
    "    ran_ind = tf.range(tmax, dtype=tf.int32)\n",
    "    ran_ind = [tf.random.shuffle(ran_ind) for i in range(batch)] # (batch, tmax)\n",
    "    ran_ind = [tf.reshape(r_i, (1,tmax)) for r_i in ran_ind] # len batch list( (tmax), ..., (tmax) )\n",
    "    ran_ind = tf.concat(ran_ind, 0) # ()\n",
    "\n",
    "    con_ind = ran_ind[:, :con_tf]\n",
    "    tar_ind = ran_ind[:, con_tf:]\n",
    "\n",
    "    T = tf.range(tmax, dtype=dt)\n",
    "    batch_T = tf.concat([tf.reshape(T, (1,tmax)) for i in range(batch)], 0) # (batch, tmax)\n",
    "\n",
    "    # time stamps of context points\n",
    "    con_T = [tf.gather(T, con_ind[i,:]) for i in range(batch)]\n",
    "    con_T = [tf.reshape(ct, (1,con_tf)) for ct in con_T]\n",
    "    con_T = tf.concat(con_T, 0)\n",
    "\n",
    "    # encoded means of contet points\n",
    "    con_lm = [tf.gather(qnet_mu[i,:,:], con_ind[i,:], axis=0) for i in range(batch)]\n",
    "    con_lm = [tf.reshape(cm, (1,con_tf,3)) for cm in con_lm]\n",
    "    con_lm = tf.concat(con_lm, 0)\n",
    "\n",
    "    # encoded variances of context points\n",
    "    con_lv = [tf.gather(qnet_var[i,:,:], con_ind[i,:], axis=0) for i in range(batch)]\n",
    "    con_lv = [tf.reshape(cv, (1,con_tf,3)) for cv in con_lv]\n",
    "    con_lv = tf.concat(con_lv, 0)\n",
    "\n",
    "    # conext Lhoods\n",
    "    _,_, con_lhoodx = build_1d_gp(con_T, con_lm[:,:,0], con_lv[:,:,0], batch_T)\n",
    "    _,_, con_lhoody = build_1d_gp(con_T, con_lm[:,:,1], con_lv[:,:,1], batch_T)\n",
    "    _,_, con_lhoodz = build_1d_gp(con_T, con_lm[:,:,2], con_lv[:,:,2], batch_T)\n",
    "    con_lhood = con_lhoodx + con_lhoody + con_lhoodz\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    #################### PriorKL 1/3: FULL APPROX POST AND LIKELIHOOD ##################\n",
    "\n",
    "    # posterior and lhood for full dataset\n",
    "    p_mx, p_vx, full_lhoodx = build_1d_gp(batch_T, qnet_mu[:,:,0], qnet_var[:,:,0], batch_T)\n",
    "    p_my, p_vy, full_lhoody = build_1d_gp(batch_T, qnet_mu[:,:,1], qnet_var[:,:,1], batch_T)\n",
    "    p_mz, p_vz, full_lhoodz = build_1d_gp(batch_T, qnet_mu[:,:,2], qnet_var[:,:,2], batch_T)\n",
    "\n",
    "    full_p_mu = tf.stack([p_mx, p_my, p_mz], axis=2)\n",
    "    full_p_var = tf.stack([p_vx, p_vy, p_vz], axis=2)\n",
    "\n",
    "    full_lhood = full_lhoodx + full_lhoody + full_lhoodz\n",
    "\n",
    "    ####################################################################################\n",
    "    ########################### PriorKL 2/3: CROSS ENTROPY TERMS #######################\n",
    "\n",
    "    # cross entropy term\n",
    "#     print(\"BHU\", full_p_var.shape, full_p_mu.shape)\n",
    "    sin_elbo_ce = gauss_cross_entropy(full_p_mu, full_p_var, qnet_mu, qnet_var) #(batch, tmax, 2)\n",
    "    sin_elbo_ce = tf.reduce_sum(sin_elbo_ce, 2) # (batch, tmax)\n",
    "\n",
    "\n",
    "    np_elbo_ce = [tf.gather(sin_elbo_ce[i,:], tar_ind[i,:]) for i in range(batch)] # (batch, con_tf)\n",
    "    np_elbo_ce = [tf.reduce_sum(np_i) for np_i in np_elbo_ce] # list of scalars, len=batch\n",
    "\n",
    "    np_elbo_ce = tf.stack(np_elbo_ce) # (batch)\n",
    "    sin_elbo_ce = tf.reduce_sum(sin_elbo_ce, 1) # (batch)\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    ################################ Prior KL 3/3 ######################################\n",
    "\n",
    "    sin_elbo_prior_kl = full_lhood - sin_elbo_ce\n",
    "    np_prior_kl       = full_lhood - np_elbo_ce - con_lhood\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    ########################### RECONSTRUCTION TERMS ###################################\n",
    "\n",
    "#     epsilon = tf.random.normal(shape=(batch, tmax, 2))\n",
    "    epsilon = tf.random.normal(shape=(batch, tmax, 3))\n",
    "    latent_samples = full_p_mu + epsilon * tf.sqrt(full_p_var)\n",
    "#     pred_vid_batch_logits = build_MLP_decoder_graph(latent_samples, px, py)\n",
    "    pred_vid_batch_logits = build_MLP_decoder_graph(latent_samples, px, py, pz)\n",
    "    pred_vid = tf.nn.sigmoid(pred_vid_batch_logits)\n",
    "    recon_err = tf.nn.sigmoid_cross_entropy_with_logits(labels=vid_batch, \n",
    "                                                        logits=pred_vid_batch_logits)\n",
    "    sin_elbo_recon = tf.reduce_sum(-recon_err, (2,3, 4)) # (batch, tmax)\n",
    "    print('BHU2',sin_elbo_recon.shape, sin_elbo_prior_kl.shape , recon_err.shape, vid_batch.shape)\n",
    "    np_elbo_recon = [tf.gather(sin_elbo_recon[i,:], tar_ind[i,:]) for i in range(batch)] # (batch, con_tf)\n",
    "    np_elbo_recon = [tf.reduce_sum(np_i) for np_i in np_elbo_recon]\n",
    "\n",
    "    # finally the reconstruction error for each objective!\n",
    "    np_elbo_recon = tf.stack(np_elbo_recon)  # (batch)\n",
    "    sin_elbo_recon = tf.reduce_sum(sin_elbo_recon, 1) # (batch)\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################################################\n",
    "    ####################### PUT IT ALL TOGETHER  ########################################\n",
    "    print('BHU2',sin_elbo_recon.shape, sin_elbo_prior_kl.shape )\n",
    "\n",
    "    sin_elbo = sin_elbo_recon + beta * sin_elbo_prior_kl\n",
    "    \n",
    "    np_elbo  = np_elbo_recon + beta * np_prior_kl\n",
    "\n",
    "    return sin_elbo, sin_elbo_recon, sin_elbo_prior_kl, \\\n",
    "           np_elbo,   np_elbo_recon,       np_prior_kl, \\\n",
    "           full_p_mu, full_p_var, \\\n",
    "           qnet_mu, qnet_var, pred_vid, globals()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e7e323df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHU0 (35, 30, 12, 12, 12)\n",
      "BHU2 (35, 30) (35,) (35, 30, 12, 12, 12) (35, 30, 12, 12, 12)\n",
      "BHU2 (35,) (35,)\n"
     ]
    }
   ],
   "source": [
    "s_elbo, s_rec, s_pkl, np_elbo, np_rec, np_pkl, \\\n",
    "    p_m,p_v,q_m,q_v,pred_vid, _ = build_sin_and_np_elbo_graphs(vid_batch, beta, lt=model_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37323ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# px=py=pz=10\n",
    "# dtype=tf.float32\n",
    "# tf_px = tf.range(px, dtype=dtype)\n",
    "# tf_py = tf.range(py, dtype=dtype)\n",
    "# tf_pz = tf.range(pz, dtype=dtype)\n",
    "# lx = tf.reshape((tf_px - paths[b,t,0])**2, (px, 1))\n",
    "# ly = tf.reshape((tf_py - paths[b,t,1])**2, (1, py))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e68c6a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://jakevdp.github.io/PythonDataScienceHandbook/04.12-three-dimensional-plotting.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439453d7",
   "metadata": {},
   "source": [
    "EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf6b3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_base_dir = os.getcwd()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train GPP-VAE')\n",
    "parser.add_argument('--steps', type=int, default=50000, help='Number of steps of Adam')\n",
    "parser.add_argument('--beta0', type=float, default=1, help='initial beta annealing value')\n",
    "parser.add_argument('--elbo', type=str, choices=['SIN', 'NP'], default='SIN',\n",
    "                     help='Structured Inf Nets ELBO or Neural Processes ELBO')\n",
    "parser.add_argument('--modellt', type=float, default=5, help='time scale of model to fit to data')\n",
    "parser.add_argument('--base_dir', type=str, default=default_base_dir, help='folder within a new dir is made for each run')\n",
    "parser.add_argument('--expid', type=str, default=\"debug\", help='give this experiment a name')\n",
    "parser.add_argument('--ram', type=float, default=0.5, help='fraction of GPU ram to use')\n",
    "parser.add_argument('--seed', type=int, default=None, help='seed for rng')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4761c486",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_base_dir = os.getcwd()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train GPP-VAE')\n",
    "parser.add_argument('--steps', type=int, default=50, help='Number of steps of Adam')\n",
    "parser.add_argument('--beta0', type=float, default=1, help='initial beta annealing value')\n",
    "parser.add_argument('--elbo', type=str, choices=['SIN', 'NP'], default='SIN',\n",
    "                     help='Structured Inf Nets ELBO or Neural Processes ELBO')\n",
    "parser.add_argument('--modellt', type=float, default=5, help='time scale of model to fit to data')\n",
    "parser.add_argument('--base_dir', type=str, default=default_base_dir, help='folder within a new dir is made for each run')\n",
    "parser.add_argument('--expid', type=str, default=\"debug\", help='give this experiment a name')\n",
    "parser.add_argument('--ram', type=float, default=0.5, help='fraction of GPU ram to use')\n",
    "parser.add_argument('--seed', type=int, default=None, help='seed for rng')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec585a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch = 35\n",
    "# tmax = 30\n",
    "# px = 32\n",
    "# py = 32\n",
    "# r = 3\n",
    "# vid_lt = 5\n",
    "# model_lt = args.modellt\n",
    "batch = 35\n",
    "tmax = 30\n",
    "px = 12\n",
    "py = 12\n",
    "pz = 12\n",
    "r = 2\n",
    "vid_lt = 5\n",
    "model_lt = args.modellt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2e68ef45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHU0 (35, 30, 12, 12, 12)\n",
      "BHU2 (35, 30) (35,) (35, 30, 12, 12, 12) (35, 30, 12, 12, 12)\n",
      "BHU2 (35,) (35,)\n"
     ]
    }
   ],
   "source": [
    "# beta = tf.compat.v1.placeholder(dtype=tf.float32, shape=())\n",
    "# vid_batch = build_video_batch_graph(batch=batch, tmax=tmax, px=px, py=py,pz=pz, r=r, lt=vid_lt)\n",
    "# s_elbo, s_rec, s_pkl, np_elbo, np_rec, np_pkl, \\\n",
    "#     p_m,p_v,q_m,q_v,pred_vid, _ = build_sin_and_np_elbo_graphs(vid_batch, beta, lt=model_lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ae30ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BHU0 (35, 30, 12, 12, 12)\n",
      "BHU2 (35, 30) (35,) (35, 30, 12, 12, 12) (35, 30, 12, 12, 12)\n",
      "BHU2 (35,) (35,)\n",
      "\n",
      "\n",
      "Trainable variables:\n",
      "<tf.Variable 'encW:0' shape=(1728, 500) dtype=float32_ref>\n",
      "<tf.Variable 'encB:0' shape=(1, 500) dtype=float32_ref>\n",
      "<tf.Variable 'encW_1:0' shape=(500, 6) dtype=float32_ref>\n",
      "<tf.Variable 'encB_1:0' shape=(1, 6) dtype=float32_ref>\n",
      "<tf.Variable 'decW:0' shape=(3, 500) dtype=float32_ref>\n",
      "<tf.Variable 'decB:0' shape=(1, 500) dtype=float32_ref>\n",
      "<tf.Variable 'decW_1:0' shape=(500, 1728) dtype=float32_ref>\n",
      "<tf.Variable 'decB_1:0' shape=(1, 1728) dtype=float32_ref>\n",
      "\n",
      "\n",
      "Initialised Model Weights\n",
      "hello 0\n",
      "hello 1\n",
      "hello 2\n",
      "hello 3\n",
      "hello 4\n",
      "hello 5\n",
      "hello 6\n",
      "hello 7\n",
      "hello 8\n",
      "hello 9\n",
      "hello 10\n",
      "hello 11\n",
      "hello 12\n",
      "hello 13\n",
      "hello 14\n",
      "hello 15\n",
      "hello 16\n",
      "hello 17\n",
      "hello 18\n",
      "hello 19\n",
      "hello 20\n",
      "hello 21\n",
      "hello 22\n",
      "hello 23\n",
      "hello 24\n",
      "hello 25\n",
      "hello 26\n",
      "hello 27\n",
      "hello 28\n",
      "hello 29\n",
      "hello 30\n",
      "hello 31\n",
      "hello 32\n",
      "hello 33\n",
      "hello 34\n",
      "hello 35\n",
      "hello 36\n",
      "hello 37\n",
      "hello 38\n",
      "hello 39\n",
      "hello 40\n",
      "hello 41\n",
      "hello 42\n",
      "hello 43\n",
      "hello 44\n",
      "hello 45\n",
      "hello 46\n",
      "hello 47\n",
      "hello 48\n",
      "hello 49\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Make all the graphs\n",
    "    beta = tf.compat.v1.placeholder(dtype=tf.float32, shape=())\n",
    "    vid_batch = build_video_batch_graph(batch=batch, tmax=tmax, px=px, py=py,pz=pz, r=r, lt=vid_lt)\n",
    "    s_elbo, s_rec, s_pkl, np_elbo, np_rec, np_pkl, \\\n",
    "        p_m,p_v,q_m,q_v,pred_vid, _ = build_sin_and_np_elbo_graphs(vid_batch, beta, lt=model_lt)\n",
    "\n",
    "    # The actual loss functions\n",
    "    if args.elbo==\"SIN\":\n",
    "        loss  = -tf.reduce_mean(s_elbo)\n",
    "        e_elb = tf.reduce_mean(s_elbo)\n",
    "        e_pkl = tf.reduce_mean(s_pkl)\n",
    "        e_rec = tf.reduce_mean(s_rec)\n",
    "    elif args.elbo==\"NP\":\n",
    "        loss  = -tf.reduce_mean(np_elbo)\n",
    "        e_elb = tf.reduce_mean(np_elbo)\n",
    "        e_pkl = tf.reduce_mean(np_pkl)\n",
    "        e_rec = tf.reduce_mean(np_rec)\n",
    "\n",
    "    av_s_elbo = tf.reduce_mean(s_elbo)\n",
    "    av_s_rec  = tf.reduce_mean(s_rec)\n",
    "    av_s_pkl  = tf.reduce_mean(s_pkl)\n",
    "\n",
    "\n",
    "    # Add optimizer ops to graph (minimizing neg elbo!), print out trainable vars\n",
    "    global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "    optimizer  = tf.compat.v1.train.AdamOptimizer()\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    optim_step = optimizer.minimize(loss=loss, \n",
    "                                    var_list=train_vars,\n",
    "                                    global_step=global_step)\n",
    "    print(\"\\n\\nTrainable variables:\")\n",
    "    for v in train_vars:\n",
    "        print(v)\n",
    "\n",
    "\n",
    "    # Initializer ops for the graph and saver\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "\n",
    "    # Results to be tracked and Pandas saver\n",
    "    res_vars = [global_step,\n",
    "                loss,\n",
    "                av_s_elbo,\n",
    "                av_s_rec,\n",
    "                av_s_pkl,\n",
    "                e_elb,\n",
    "                e_rec,\n",
    "                e_pkl,\n",
    "                tf.math.reduce_min(q_v),\n",
    "                tf.math.reduce_max(q_v),\n",
    "                tf.math.reduce_min(p_v),\n",
    "                tf.math.reduce_max(p_v)]\n",
    "    res_names= [\"Step\",\n",
    "                \"Loss\",\n",
    "                \"Test ELBO\",\n",
    "                \"Test Reconstruction\",\n",
    "                \"Test Prior KL\",\n",
    "                \"Train ELBO\",\n",
    "                \"Train Reconstruction\",\n",
    "                \"Train Prior KL\",\n",
    "                \"min qs_var\",\n",
    "                \"max qs_var\",\n",
    "                \"min q_var\",\n",
    "                \"max q_var\",\n",
    "                \"MSE\",\n",
    "                \"Beta\",\n",
    "                \"Time\"]\n",
    "        # Now let's start doing some computation!\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.ram)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "\n",
    "        # Attempt to restore weights\n",
    "        try:\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(chkpnt_dir))\n",
    "            print(\"\\n\\nRestored Model Weights\")\n",
    "        except:\n",
    "            sess.run(init_op)\n",
    "            print(\"\\n\\nInitialised Model Weights\")\n",
    "\n",
    "        # Start training that elbo!\n",
    "        for t in range(args.steps):\n",
    "\n",
    "            # Annealing factor for prior KL\n",
    "            beta_t = 1 + (args.beta0-1) * np.exp(t/2000)\n",
    "            print(\"hello\", t)\n",
    "\n",
    "            # Train: do an optim step\n",
    "            _, g_s = sess.run([optim_step, global_step], {beta:beta_t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5ab29b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HE\n"
     ]
    }
   ],
   "source": [
    "print(\"HE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e87fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
