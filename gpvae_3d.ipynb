{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2caf9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "from tensorflow.python.ops import math_ops as tfmath_ops\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916a07da",
   "metadata": {},
   "source": [
    "## Utility function for data generation\n",
    "Source code copied from [this repo](https://github.com/scrambledpie/GPVAE) and changed to generate and work with 3d data  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef90e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Make_path_batch(batch=40, tmax=30, lt=5, seed=None):\n",
    "    \"\"\"\n",
    "    Samples x(t), y(t) from a GP\n",
    "    args:\n",
    "        batch: number of samples\n",
    "        tmax: length of samples\n",
    "        lt: GP length scale\n",
    "    returns:\n",
    "        traj: nparray (batch, tmax, 2)\n",
    "    \"\"\"\n",
    "    ilt = -0.5/(lt*lt)\n",
    "    T = np.arange(tmax)\n",
    "    Sigma = np.exp( ilt * (T.reshape(-1,1) - T.reshape(1,-1))**2)\n",
    "    Mu = np.zeros(tmax)\n",
    "    np.random.seed(seed)\n",
    "    traj = np.random.multivariate_normal(Mu, Sigma, (batch, 3))\n",
    "    traj = np.transpose(traj, (0,2,1))\n",
    "    return traj\n",
    "\n",
    "def Make_Video_batch(tmax=50, px=10, py=10, pz=10,  lt=5,  batch=40, seed=1, r=2):\n",
    "    \"\"\"\n",
    "    params:\n",
    "        tmax: number of frames to generate\n",
    "        px: horizontal resolution\n",
    "        py: vertical resolution\n",
    "        lt: length scale\n",
    "        batch: number of videos\n",
    "        seed: rng seed\n",
    "        r: radius of ball in pixels\n",
    "    returns:\n",
    "        traj0: (batch, tmax, 2) numpy array\n",
    "        vid_batch: (batch, tmax, px, py) numpy array\n",
    "    \"\"\"\n",
    "    traj0 = Make_path_batch(batch=batch, tmax=tmax, lt=lt, seed=seed)\n",
    "    traj = traj0.copy()\n",
    "    traj[:,:,0] = traj[:,:,0] * (px/5) + (0.5*px)\n",
    "    traj[:,:,1] = traj[:,:,1] * (py/5) + (0.5*py)\n",
    "    traj[:,:,2] = traj[:,:,2] * (pz/5) + (0.5*pz)\n",
    "    rr = r*r*r\n",
    "    def pixelate_frame(xyz):\n",
    "        \"\"\"\n",
    "        takes a single x,y pixel point and converts to binary image\n",
    "        with ball centered at x,y.\n",
    "        \"\"\"\n",
    "        x = xyz[0]\n",
    "        y = xyz[1]\n",
    "        z = xyz[2]\n",
    "        sq_x = (np.arange(px) - x)**2\n",
    "        sq_y = (np.arange(py) - y)**2\n",
    "        sq_z = (np.arange(pz) - z)**2\n",
    "        lx = tf.reshape(sq_x, (px, 1, 1))\n",
    "        ly = tf.reshape(sq_x, (1, py, 1))\n",
    "        lz = tf.reshape(sq_z, (1,1, pz))\n",
    "        image = lx + ly +lz< rr\n",
    "        return image\n",
    "    \n",
    "    def pixelate_series(XYZ):\n",
    "        vid = map(pixelate_frame, XYZ)\n",
    "        vid = [v for v in vid]\n",
    "        return np.asarray(vid)\n",
    "    vid_batch = [pixelate_series(traj_i) for traj_i in traj]\n",
    "    vid_batch = np.asarray(vid_batch)\n",
    "    return traj0, vid_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a579ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_cross_entropy(mu1, var1, mu2, var2):\n",
    "    \"\"\"\n",
    "    Computes the element-wise cross entropy\n",
    "    Given q(z) ~ N(z| mu1, var1)\n",
    "    returns E_q[ log N(z| mu2, var2) ]\n",
    "    args:\n",
    "        mu1:  mean of expectation (batch, tmax, 2) tf variable\n",
    "        var1: var  of expectation (batch, tmax, 2) tf variable\n",
    "        mu2:  mean of integrand (batch, tmax, 2) tf variable\n",
    "        var2: var of integrand (batch, tmax, 2) tf variable\n",
    "\n",
    "    returns:\n",
    "        cross_entropy: (batch, tmax, 2) tf variable\n",
    "    \"\"\"\n",
    "    term0 = 1.8378770664093453 # log(2*pi)\n",
    "    term1 = tf.log(var2)\n",
    "    term2 = (var1 + mu1**2 - 2*mu1*mu2 + mu2**2) / var2\n",
    "    cross_entropy = -0.5*( term0 + term1 + term2 )\n",
    "    return cross_entropy\n",
    "\n",
    "def gauss_entropy(var1):\n",
    "    \"\"\"\n",
    "    Computes the element-wise entropy\n",
    "    Given q(z) ~ N(z| mu1, var1)\n",
    "    returns E_q[ log N(z| mu1, var1) ] = -0.5 ( log(var1) + 1 + log(2*pi) )\n",
    "    args:\n",
    "        var1: var  of expectation (batch, tmax, 2) tf variable\n",
    "\n",
    "    returns:\n",
    "        cross_entropy: (batch, tmax, 2) tf variable\n",
    "    \"\"\"\n",
    "    term0 = tf.log(var1) + 2.8378770664093453 # 1 + log(2*pi)\n",
    "    cross_entropy = -0.5*( term0 )\n",
    "    return cross_entropy\n",
    "\n",
    "def MSE_rotation(X, Y, VX=None):\n",
    "    \"\"\"\n",
    "    Given X, rotate it onto Y\n",
    "    args:\n",
    "        X: np array (batch, tmax, 2)\n",
    "        Y: np array (batch, tmax, 2)\n",
    "        VX: variance of X values (batch, tmax, 2)\n",
    "\n",
    "    returns:\n",
    "        X_rot: rotated X (batch, tmax, 2)\n",
    "        W: nparray (2, 2)\n",
    "        B: nparray (2, 1)\n",
    "        MSE: ||X_rot - Y||^2\n",
    "        VX_rot: rotated cov matrices (default zeros)\n",
    "    \"\"\"\n",
    "    batch, tmax, _ = X.shape\n",
    "    X = X.reshape((batch*tmax, 3))\n",
    "    X = np.hstack([X, np.ones((batch*tmax, 1))])\n",
    "    Y = Y.reshape(batch*tmax, 3)\n",
    "    W, MSE, _, _ = np.linalg.lstsq(X, Y, rcond=None)\n",
    "    try:\n",
    "        MSE = MSE[0] + MSE[1]\n",
    "    except:\n",
    "        MSE = np.nan\n",
    "    X_rot = np.matmul(X, W)\n",
    "    X_rot = X_rot.reshape(batch, tmax, 3)\n",
    "    VX_rot = np.zeros((batch, tmax, 3, 3))\n",
    "    if VX is not None:\n",
    "        W_rot = W[:3,:]\n",
    "        W_rot_t = np.transpose(W[:3,:])\n",
    "        for b in range(batch):\n",
    "            for t in range(tmax):\n",
    "                VX_i = np.diag(VX[b,t,:])\n",
    "                VX_i = np.matmul(W_rot, VX_i)\n",
    "                VX_i = np.matmul(VX_i, W_rot_t)\n",
    "                VX_rot[b,t,:,:] = VX_i\n",
    "\n",
    "    return X_rot, W, MSE, VX_rot\n",
    "\n",
    "\n",
    "def build_MLP_inference_graph(vid_batch, layers=[500], tftype=tf.float32):\n",
    "    \"\"\"\n",
    "    Takes a placeholder for batches of videos to be fed in, returns \n",
    "    a mean and var of 2d latent space that are tf variables.\n",
    "\n",
    "    args:\n",
    "        vid_batch: tf placeholder (batch, tmax, width, height)\n",
    "        layers: list of widths of fully connected layers\n",
    "        tftype: data type to use in graph\n",
    "\n",
    "    returns:\n",
    "        means:  tf variable, (batch, tmax, 2) x,y points\n",
    "        vars:  tf variable, (batch, tmax, 2) x,y uncertainties\n",
    "    \"\"\"\n",
    "    batch, tmax, px, py, pz = vid_batch.get_shape()\n",
    "    # first layer, flatten images to vectors\n",
    "    h0 = tf.reshape(vid_batch, (batch*tmax, px*py))\n",
    "    # loop over layers in given list\n",
    "    for l in layers:\n",
    "        i_dims = int(h0.get_shape()[-1])\n",
    "        W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "                stddev=1.0 / np.sqrt(float(i_dims))), name=\"encW\")\n",
    "        B = tf.Variable(tf.zeros([1, l]), name=\"encB\")\n",
    "        h0 = tf.matmul(h0, W) + B\n",
    "        h0 = tf.nn.tanh(h0)\n",
    "    # final layer just outputs x,y mean and log(var) of q network\n",
    "    i_dims = int(h0.get_shape()[-1])\n",
    "    W = tf.Variable(tf.truncated_normal([i_dims, 6],\n",
    "            stddev=1.0 / np.sqrt(float(i_dims))), name=\"encW\")\n",
    "    B = tf.Variable(tf.zeros([1, 6]), name=\"encB\")\n",
    "    h0 = tf.matmul(h0, W) + B\n",
    "    h0 = tf.reshape(h0, (batch, tmax, 6))\n",
    "    #First 2 mean Next 2 variance\n",
    "    q_means = h0[:, :, :3]\n",
    "    q_vars  = tf.exp(h0[:, :, 3:])\n",
    "\n",
    "    return q_means, q_vars\n",
    "\n",
    "def build_MLP_decoder_graph(latent_samples, px, py, layers=[500]):\n",
    "    \"\"\"\n",
    "    Constructs a TF graph that goes from latent points in 2D time series\n",
    "    to a bernoulli probabilty for each pixel in output video time series.\n",
    "    Args:\n",
    "        latent_samples: (batch, tmax, 2), tf variable\n",
    "        px: image width (int)\n",
    "        py: image height (int)\n",
    "        layers: list of num. of nodes (list of ints)\n",
    "\n",
    "    Returns:\n",
    "        pred_batch_vid_logits: (batch, tmax, px, py) tf variable\n",
    "    \"\"\"\n",
    "    batch, tmax, _ = latent_samples.get_shape()\n",
    "    # flatten all latents into one matrix (decoded in i.i.d fashion)\n",
    "    h0 = tf.reshape(latent_samples, (batch*tmax, 3))\n",
    "\n",
    "    # loop over layers in given list\n",
    "    for l in layers:\n",
    "        i_dims = int(h0.get_shape()[-1])\n",
    "        W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "                stddev=1.0 / np.sqrt(float(i_dims))), name=\"decW\")\n",
    "        B = tf.Variable(tf.zeros([1, l]), name=\"decB\")\n",
    "        h0 = tf.matmul(h0, W) + B\n",
    "        h0 = tf.nn.tanh(h0)\n",
    "\n",
    "    # final layer just outputs full video batch\n",
    "    l = px*py\n",
    "    i_dims = int(h0.get_shape()[-1])\n",
    "    W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "            stddev=1.0 / np.sqrt(float(i_dims))), name=\"decW\")\n",
    "    B = tf.Variable(tf.zeros([1, l]), name=\"decB\")\n",
    "    h0 = tf.matmul(h0, W) + B\n",
    "    pred_vid_batch_logits = tf.reshape(h0, (batch, tmax, px, py))\n",
    "    return pred_vid_batch_logits\n",
    "\n",
    "def build_1d_gp(X, Y, varY, X_test, lt=5):\n",
    "    \"\"\"\n",
    "    Takes input-output dataset and returns post mean, var, marginal lhood.\n",
    "    This is standard GP regression (in this application X is time, Y is \n",
    "    recognition network means with noise as recognition netowrk variance).\n",
    "\n",
    "    Args:\n",
    "        X: inputs tensor (batch, npoints)\n",
    "        Y: outputs tensor (batch, npoints)\n",
    "        varY: noise of outputs tensor (batch, npoints)\n",
    "        X_test: (batch, ns) input points to compute post mean + var\n",
    "\n",
    "    Returns:\n",
    "        p_m: (batch, ns) post mean at X_test\n",
    "        p_v: (batch, ns) post var at X_test\n",
    "        logZ: (batch) marginal lhood of each dataset in batch\n",
    "    \"\"\"\n",
    "    # Prepare all constants\n",
    "    batch, _ = X.get_shape()\n",
    "    n = tf.shape(X)[1]\n",
    "    _, ns = X_test.get_shape()\n",
    "    # inverse square length scale\n",
    "    ilt = tf.constant( -0.5*(1/(lt*lt)) )\n",
    "    # lhood term 1/3\n",
    "    lhood_pi_term = tf.cast(n, dtype=tf.float32) * np.log(2*np.pi)\n",
    "    # data cov matrix K = exp( -1/2 * (X-X)**2/l**2) + noise\n",
    "    K = tf.reshape(X, (batch, n, 1)) - tf.reshape(X, (batch, 1, n)) # (batch, n n)\n",
    "    K = tf.exp( (K**2) * ilt)  + tf.matrix_diag(varY) \n",
    "    chol_K = tf.linalg.cholesky(K) # (batch, n, n)\n",
    "    # lhood term 2/3\n",
    "    lhood_logdet_term = 2*tf.reduce_sum(tf.log(tf.matrix_diag_part(chol_K)), 1) # (batch)\n",
    "    # lhood term 3/3\n",
    "    Y = tf.reshape(Y, (batch, n, 1))\n",
    "    iKY = tf.cholesky_solve( chol_K, Y) # (batch, n, 1)\n",
    "    lh_quad_term = tf.matmul(tf.reshape(Y, (batch, 1, n)), iKY) # (batch, 1, 1)\n",
    "    lh_quad_term = tf.reshape(lh_quad_term, [batch])\n",
    "    # log P(Y|X) = -1/2 * ( n log(2 pi) + Y inv(K+noise) Y + log det(K+noise))\n",
    "    gp_lhood = -0.5*( lhood_pi_term + lh_quad_term + lhood_logdet_term )\n",
    "    # Compute posterior mean and variances\n",
    "    Ks = tf.reshape(X, (batch, n, 1)) - tf.reshape(X_test, (batch, 1, ns)) #broadcasts to (batch, n, ns)\n",
    "    Ks = tf.exp( (Ks**2) * ilt) # (batch, n, ns)\n",
    "    Ks_t = tf.transpose(Ks, (0, 2, 1)) # (batch, ns, n)\n",
    "    # posterior mean\n",
    "    p_m = tf.matmul(Ks_t, iKY)\n",
    "    p_m = tf.reshape(p_m, (batch, ns))\n",
    "    # posterior variance\n",
    "    iK_Ks = tf.cholesky_solve(chol_K, Ks) # (batch, n, ns)\n",
    "    Ks_iK_Ks = tf.reduce_sum(Ks * iK_Ks, axis=1) # (batch, ns)\n",
    "    p_v = 1 - Ks_iK_Ks # (batch, ns)\n",
    "    p_v = tf.reshape(p_v, (batch, ns))\n",
    "    return p_m, p_v, gp_lhood\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c7f72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_video_batch_graph(tmax=50, px=10, py=10, pz=10, lt=5, batch=1, seed=1, r=2, dtype=tf.float32):\n",
    "    rr = r*r*r\n",
    "    ilt = tf.constant(-0.5/(lt**2), dtype=dtype)\n",
    "    K = tf.range(tmax, dtype=dtype)\n",
    "    K = (tf.reshape(K, (tmax, 1)) - tf.reshape(K, (1, tmax)))**2\n",
    "    K = tf.exp(K*ilt) + 0.00001*tf.eye(tmax, dtype=dtype)\n",
    "    chol_K = tf.Variable(tf.linalg.cholesky(K), trainable=False)\n",
    "    ran_Z = tf.random.normal((tmax, 3*batch))\n",
    "    paths = tf.matmul(chol_K, ran_Z)\n",
    "    paths = tf.reshape(paths, (tmax, batch, 3))\n",
    "    paths = tf.transpose(paths, (1,0,2))\n",
    "    # assumes px = py\n",
    "    paths = paths*0.2*px + 0.5*px\n",
    "    vid_batch = []\n",
    "    tf_px = tf.range(px, dtype=dtype)\n",
    "    tf_py = tf.range(py, dtype=dtype)\n",
    "    tf_pz = tf.range(pz, dtype=dtype)\n",
    "    for b in range(batch):\n",
    "        frames_tmax = []\n",
    "        for t in range(tmax):\n",
    "            lx = tf.reshape((tf_px - paths[b,t,0])**2, (px, 1, 1))\n",
    "            ly = tf.reshape((tf_py - paths[b,t,1])**2, (1, py, 1))\n",
    "            lz = tf.reshape((tf_py - paths[b,t,2])**2, (1,1, pz))\n",
    "            frame = lx + ly +lz< rr\n",
    "            frames_tmax.append(tf.reshape(frame, (1,1,px,py, pz)))\n",
    "        vid_batch.append(tf.concat(frames_tmax, 1))\n",
    "    vid_batch = [tfmath_ops.cast(vid, dtype=dtype) for vid in vid_batch]\n",
    "    vid_batch = tf.concat(vid_batch, 0)\n",
    "    return vid_batch\n",
    "\n",
    "def build_MLP_inference_graph(vid_batch, layers=[500], tftype=tf.float32):\n",
    "    \"\"\"\n",
    "    Takes a placeholder for batches of videos to be fed in, returns \n",
    "    a mean and var of 2d latent space that are tf variables.\n",
    "\n",
    "    args:\n",
    "        vid_batch: tf placeholder (batch, tmax, width, height)\n",
    "        layers: list of widths of fully connected layers\n",
    "        tftype: data type to use in graph\n",
    "\n",
    "    returns:\n",
    "        means:  tf variable, (batch, tmax, 2) x,y points\n",
    "        vars:  tf variable, (batch, tmax, 2) x,y uncertainties\n",
    "    \"\"\"\n",
    "    batch, tmax, px, py ,pz = vid_batch.get_shape()\n",
    "    # first layer, flatten images to vectors\n",
    "    h0 = tf.reshape(vid_batch, (batch*tmax, px*py*pz))\n",
    "    # loop over layers in given list\n",
    "    for l in layers:\n",
    "        i_dims = int(h0.get_shape()[-1])\n",
    "        W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "                stddev=1.0 / np.sqrt(float(i_dims))), name=\"encW\")\n",
    "        B = tf.Variable(tf.zeros([1, l]), name=\"encB\")\n",
    "        h0 = tf.matmul(h0, W) + B\n",
    "        h0 = tf.nn.tanh(h0)\n",
    "    # final layer just outputs x,y mean and log(var) of q network\n",
    "    i_dims = int(h0.get_shape()[-1])\n",
    "    W = tf.Variable(tf.truncated_normal([i_dims, 6],\n",
    "            stddev=1.0 / np.sqrt(float(i_dims))), name=\"encW\")\n",
    "    B = tf.Variable(tf.zeros([1, 6]), name=\"encB\")\n",
    "    h0 = tf.matmul(h0, W) + B\n",
    "    h0 = tf.reshape(h0, (batch, tmax, 6))\n",
    "    q_means = h0[:, :, :3]\n",
    "    q_vars  = tf.exp(h0[:, :, 3:])\n",
    "    return q_means, q_vars\n",
    "def build_MLP_decoder_graph(latent_samples, px, py,pz, layers=[500]):\n",
    "    \"\"\"\n",
    "    Constructs a TF graph that goes from latent points in 2D time series\n",
    "    to a bernoulli probabilty for each pixel in output video time series.\n",
    "    Args:\n",
    "        latent_samples: (batch, tmax, 2), tf variable\n",
    "        px: image width (int)\n",
    "        py: image height (int)\n",
    "        layers: list of num. of nodes (list of ints)\n",
    "\n",
    "    Returns:\n",
    "        pred_batch_vid_logits: (batch, tmax, px, py) tf variable\n",
    "    \"\"\"\n",
    "    batch, tmax, _ = latent_samples.get_shape()\n",
    "    h0 = tf.reshape(latent_samples, (batch*tmax, 3))\n",
    "    # loop over layers in given list\n",
    "    for l in layers:\n",
    "        i_dims = int(h0.get_shape()[-1])\n",
    "        W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "                stddev=1.0 / np.sqrt(float(i_dims))), name=\"decW\")\n",
    "        B = tf.Variable(tf.zeros([1, l]), name=\"decB\")\n",
    "        h0 = tf.matmul(h0, W) + B\n",
    "        h0 = tf.nn.tanh(h0)\n",
    "\n",
    "    # final layer just outputs full video batch\n",
    "    l = px*py*pz\n",
    "    i_dims = int(h0.get_shape()[-1])\n",
    "    W = tf.Variable(tf.truncated_normal([i_dims, l],\n",
    "            stddev=1.0 / np.sqrt(float(i_dims))), name=\"decW\")\n",
    "    B = tf.Variable(tf.zeros([1, l]), name=\"decB\")\n",
    "    h0 = tf.matmul(h0, W) + B\n",
    "    pred_vid_batch_logits = tf.reshape(h0, (batch, tmax, px, py, pz))\n",
    "    return pred_vid_batch_logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f31e86cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sin_and_np_elbo_graphs(vid_batch, beta, lt=5, context_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Builds both standard (sin) eblo and neural process (np) elbo. \n",
    "    Returns pretty much everything!\n",
    "    Args:\n",
    "        vid_batch: tf variable (batch, tmax, px, py) binay arrays or images\n",
    "        beta: scalar, tf variable, annealing term for prior KL\n",
    "        lt: length scale of GP\n",
    "        context_ratio: float in [0,1], for np elbo, random target-context split ratio\n",
    "\n",
    "    Returns:\n",
    "        sin_elbo: \"standard\" elbo\n",
    "        sin_elbo_recon: recon struction term\n",
    "        sin_elbo_prior_kl: prior KL term\n",
    "        np_elbo: neural process elbo\n",
    "        np_elbo_recon: ...\n",
    "        np_prior_kl: ...\n",
    "        full_p_mu: approx posterior mean\n",
    "        full_p_var: approx post var\n",
    "        qnet_mu: recognition network mean\n",
    "        qnet_var: recog. net var\n",
    "        pred_vid: reconstructed video\n",
    "        globals(): aaaalll variables in local scope\n",
    "    \"\"\"\n",
    "    batch, tmax, px, py, pz= [int(s) for s in vid_batch.get_shape()]\n",
    "\n",
    "    # Choose a random split of target-context for each batch\n",
    "    con_tf = tf.random.normal(shape=(),\n",
    "                              mean=context_ratio*float(tmax),\n",
    "                              stddev=np.sqrt(context_ratio*(1-context_ratio)*float(tmax)))\n",
    "    con_tf = tf.math.maximum(con_tf, 2)\n",
    "    con_tf = tf.math.minimum(con_tf, int(tmax)-2)\n",
    "    con_tf = tf.cast(tf.round(con_tf), tf.int32)\n",
    "\n",
    "    dt = vid_batch.dtype\n",
    "    \n",
    "    # recognition network terms\n",
    "    qnet_mu, qnet_var = build_MLP_inference_graph(vid_batch)\n",
    "\n",
    "    ##################################################################\n",
    "    ####################### CONTEXT LIKELIHOOD #######################\n",
    "    # make random indices\n",
    "    ran_ind = tf.range(tmax, dtype=tf.int32)\n",
    "    ran_ind = [tf.random.shuffle(ran_ind) for i in range(batch)] # (batch, tmax)\n",
    "    ran_ind = [tf.reshape(r_i, (1,tmax)) for r_i in ran_ind] # len batch list( (tmax), ..., (tmax) )\n",
    "    ran_ind = tf.concat(ran_ind, 0) # ()\n",
    "\n",
    "    con_ind = ran_ind[:, :con_tf]\n",
    "    tar_ind = ran_ind[:, con_tf:]\n",
    "\n",
    "    T = tf.range(tmax, dtype=dt)\n",
    "    batch_T = tf.concat([tf.reshape(T, (1,tmax)) for i in range(batch)], 0) # (batch, tmax)\n",
    "\n",
    "    # time stamps of context points\n",
    "    con_T = [tf.gather(T, con_ind[i,:]) for i in range(batch)]\n",
    "    con_T = [tf.reshape(ct, (1,con_tf)) for ct in con_T]\n",
    "    con_T = tf.concat(con_T, 0)\n",
    "\n",
    "    # encoded means of contet points\n",
    "    con_lm = [tf.gather(qnet_mu[i,:,:], con_ind[i,:], axis=0) for i in range(batch)]\n",
    "    con_lm = [tf.reshape(cm, (1,con_tf,3)) for cm in con_lm]\n",
    "    con_lm = tf.concat(con_lm, 0)\n",
    "\n",
    "    # encoded variances of context points\n",
    "    con_lv = [tf.gather(qnet_var[i,:,:], con_ind[i,:], axis=0) for i in range(batch)]\n",
    "    con_lv = [tf.reshape(cv, (1,con_tf,3)) for cv in con_lv]\n",
    "    con_lv = tf.concat(con_lv, 0)\n",
    "\n",
    "    # conext Lhoods\n",
    "    _,_, con_lhoodx = build_1d_gp(con_T, con_lm[:,:,0], con_lv[:,:,0], batch_T)\n",
    "    _,_, con_lhoody = build_1d_gp(con_T, con_lm[:,:,1], con_lv[:,:,1], batch_T)\n",
    "    _,_, con_lhoodz = build_1d_gp(con_T, con_lm[:,:,2], con_lv[:,:,2], batch_T)\n",
    "    con_lhood = con_lhoodx + con_lhoody + con_lhoodz\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    #################### PriorKL 1/3: FULL APPROX POST AND LIKELIHOOD ##################\n",
    "\n",
    "    # posterior and lhood for full dataset\n",
    "    p_mx, p_vx, full_lhoodx = build_1d_gp(batch_T, qnet_mu[:,:,0], qnet_var[:,:,0], batch_T)\n",
    "    p_my, p_vy, full_lhoody = build_1d_gp(batch_T, qnet_mu[:,:,1], qnet_var[:,:,1], batch_T)\n",
    "    p_mz, p_vz, full_lhoodz = build_1d_gp(batch_T, qnet_mu[:,:,2], qnet_var[:,:,2], batch_T)\n",
    "\n",
    "    full_p_mu = tf.stack([p_mx, p_my, p_mz], axis=2)\n",
    "    full_p_var = tf.stack([p_vx, p_vy, p_vz], axis=2)\n",
    "\n",
    "    full_lhood = full_lhoodx + full_lhoody + full_lhoodz\n",
    "\n",
    "    ####################################################################################\n",
    "    ########################### PriorKL 2/3: CROSS ENTROPY TERMS #######################\n",
    "\n",
    "    # cross entropy term\n",
    "    sin_elbo_ce = gauss_cross_entropy(full_p_mu, full_p_var, qnet_mu, qnet_var) #(batch, tmax, 2)\n",
    "    sin_elbo_ce = tf.reduce_sum(sin_elbo_ce, 2) # (batch, tmax)\n",
    "\n",
    "\n",
    "    np_elbo_ce = [tf.gather(sin_elbo_ce[i,:], tar_ind[i,:]) for i in range(batch)] # (batch, con_tf)\n",
    "    np_elbo_ce = [tf.reduce_sum(np_i) for np_i in np_elbo_ce] # list of scalars, len=batch\n",
    "\n",
    "    np_elbo_ce = tf.stack(np_elbo_ce) # (batch)\n",
    "    sin_elbo_ce = tf.reduce_sum(sin_elbo_ce, 1) # (batch)\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    ################################ Prior KL 3/3 ######################################\n",
    "\n",
    "    sin_elbo_prior_kl = full_lhood - sin_elbo_ce\n",
    "    np_prior_kl       = full_lhood - np_elbo_ce - con_lhood\n",
    "\n",
    "\n",
    "    ####################################################################################\n",
    "    ########################### RECONSTRUCTION TERMS ###################################\n",
    "\n",
    "    epsilon = tf.random.normal(shape=(batch, tmax, 3))\n",
    "    latent_samples = full_p_mu + epsilon * tf.sqrt(full_p_var)\n",
    "    pred_vid_batch_logits = build_MLP_decoder_graph(latent_samples, px, py, pz)\n",
    "    pred_vid = tf.nn.sigmoid(pred_vid_batch_logits)\n",
    "    recon_err = tf.nn.sigmoid_cross_entropy_with_logits(labels=vid_batch, \n",
    "                                                        logits=pred_vid_batch_logits)\n",
    "    sin_elbo_recon = tf.reduce_sum(-recon_err, (2,3, 4)) # (batch, tmax)\n",
    "    np_elbo_recon = [tf.gather(sin_elbo_recon[i,:], tar_ind[i,:]) for i in range(batch)] # (batch, con_tf)\n",
    "    np_elbo_recon = [tf.reduce_sum(np_i) for np_i in np_elbo_recon]\n",
    "\n",
    "    # finally the reconstruction error for each objective!\n",
    "    np_elbo_recon = tf.stack(np_elbo_recon)  # (batch)\n",
    "    sin_elbo_recon = tf.reduce_sum(sin_elbo_recon, 1) # (batch)\n",
    "\n",
    "\n",
    "\n",
    "    #####################################################################################\n",
    "    ####################### PUT IT ALL TOGETHER  ########################################\n",
    "\n",
    "    sin_elbo = sin_elbo_recon + beta * sin_elbo_prior_kl\n",
    "    \n",
    "    np_elbo  = np_elbo_recon + beta * np_prior_kl\n",
    "\n",
    "    return sin_elbo, sin_elbo_recon, sin_elbo_prior_kl, \\\n",
    "           np_elbo,   np_elbo_recon,       np_prior_kl, \\\n",
    "           full_p_mu, full_p_var, \\\n",
    "           qnet_mu, qnet_var, pred_vid, globals()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439453d7",
   "metadata": {},
   "source": [
    "## TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4016b81",
   "metadata": {},
   "source": [
    "### Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd0dd64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_base_dir = os.getcwd()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train GPP-VAE')\n",
    "parser.add_argument('--steps', type=int, default=50000, help='Number of steps of Adam')\n",
    "parser.add_argument('--beta0', type=float, default=1, help='initial beta annealing value')\n",
    "parser.add_argument('--elbo', type=str, choices=['SIN', 'NP'], default='SIN',\n",
    "                     help='Structured Inf Nets ELBO or Neural Processes ELBO')\n",
    "parser.add_argument('--modellt', type=float, default=5, help='time scale of model to fit to data')\n",
    "parser.add_argument('--base_dir', type=str, default=default_base_dir, help='folder within a new dir is made for each run')\n",
    "parser.add_argument('--expid', type=str, default=\"debug\", help='give this experiment a name')\n",
    "parser.add_argument('--ram', type=float, default=0.5, help='fraction of GPU ram to use')\n",
    "parser.add_argument('--seed', type=int, default=None, help='seed for rng')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd238e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 35\n",
    "tmax = 30\n",
    "px = py = pz =16\n",
    "r = 2\n",
    "vid_lt = 5\n",
    "model_lt = args.modellt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f62b94e",
   "metadata": {},
   "source": [
    "## Plotting Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d59baba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSeris(M):\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    colmap =[]\n",
    "    for i in range(16):\n",
    "        for j in range(16):\n",
    "            for k in range(16):\n",
    "                x.append(i)\n",
    "                y.append(j)\n",
    "                z.append(k)\n",
    "                colmap.append(M[i][j][k])\n",
    "    return x,y,z,colmap \n",
    "\n",
    "\n",
    "def plot_latents(truepath, reconpath=None, fig=None, nplots=4):\n",
    "    \"\"\"\n",
    "    Plots an array of input videos and reconstructions.\n",
    "    args:\n",
    "        truevids: (batch, tmax, px, py) np array of videos\n",
    "        truepath: (batch, tmax, 2) np array of latent positions\n",
    "        reconvids: (batch, tmax, px, py) np array of videos\n",
    "        reconpath: (batch, tmax, 2) np array of latent positions\n",
    "        reconvar: (batch, tmax, 2, 2) np array, cov mat \n",
    "        ax: (optional) list of lists of axes objects for plotting\n",
    "        nplots: int, number of rows of plot, each row is one video\n",
    "        paths: (batch, tmax, 2) np array optional extra array to plot\n",
    "\n",
    "    returns:\n",
    "        fig: figure object with all plots\n",
    "\n",
    "    \"\"\"\n",
    "    tmax = truepath.shape[1]\n",
    "    # get axis limits for the latent space\n",
    "    xmin = np.min([truepath[:nplots,:,0].min(), \n",
    "                   reconpath[:nplots,:,0].min()]) -0.1\n",
    "    xmin = np.min([xmin, -2.5])\n",
    "    xmax = np.max([truepath[:nplots,:,0].max(), \n",
    "                   reconpath[:nplots,:,0].max()]) +0.1\n",
    "    xmax = np.max([xmax, 2.5])\n",
    "\n",
    "    ymin = np.min([truepath[:nplots,:,1].min(), \n",
    "                   reconpath[:nplots,:,1].min()]) -0.1\n",
    "    ymin = np.min([ymin, -2.5])\n",
    "    ymax = np.max([truepath[:nplots,:,1].max(), \n",
    "                   reconpath[:nplots,:,1].max()]) +0.1\n",
    "    ymax = np.max([xmax, 2.5])\n",
    "    \n",
    "    zmin = np.min([truepath[:nplots,:,2].min(), \n",
    "                   reconpath[:nplots,:,2].min()]) -0.1\n",
    "    zmin = np.min([zmin, -2.5])\n",
    "    zmax = np.max([truepath[:nplots,:,2].max(), \n",
    "                   reconpath[:nplots,:,2].max()]) +0.1\n",
    "    zmax = np.max([xmax, 2.5])\n",
    "    def plot_set(i):\n",
    "        n = 200+nplots*10+i+1+nplots\n",
    "        ax = fig.add_subplot(n, projection='3d')\n",
    "        ax.plot(truepath[i,:,0], truepath[i,:,1], truepath[i,:,2])\n",
    "        ax.set_xlim([xmin, xmax])\n",
    "        ax.set_ylim([ymin, ymax])\n",
    "        ax.set_ylim([zmin, zmax])\n",
    "        ax.scatter(truepath[i,-1,0], truepath[i,-1,1], truepath[i,-1,2])\n",
    "        \n",
    "        if reconpath is not None:\n",
    "            ax.plot(reconpath[i,:,0], reconpath[i,:,1],  reconpath[i,:,2])\n",
    "            ax.scatter(reconpath[i,-1,0], reconpath[i,-1,1], reconpath[i,-1,2])\n",
    "    for i in range(nplots):\n",
    "        plot_set(i)\n",
    "\n",
    "def plot_reconstruction(TD, reconvid, TT, rp, iteration, px = 16, nplots = 3):\n",
    "    fig = plt.figure(figsize=(10, 7))\n",
    "    fig.suptitle(f\"ITERATION {iteration}\")\n",
    "    b = 200+nplots*10\n",
    "    for i in range(nplots):\n",
    "        n = b+i+1\n",
    "        ax = fig.add_subplot(n, projection='3d')\n",
    "        ax.set_xlim(0,px)\n",
    "        ax.set_ylim(0,px)\n",
    "        ax.set_zlim(0,px)\n",
    "        for j in range(TD.shape[1]):\n",
    "            z,x,y = TD[i][j].nonzero()\n",
    "            ax.scatter(x, y, z, zdir='z',cmap='Greys')\n",
    "        plot_latents(TT, reconpath= rp, fig=fig, nplots=nplots)    \n",
    "    plt.savefig(\"result_final.png\")\n",
    "    plt.pause(0.5);\n",
    "    clear_output(wait=True);        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c2c34",
   "metadata": {},
   "source": [
    "### Training and eval loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30ed20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 10559\n"
     ]
    }
   ],
   "source": [
    "make_batch = lambda s: Make_Video_batch(tmax=tmax, px=px, py=py, pz=pz, lt=vid_lt, batch=batch, seed=s, r=r)\n",
    "Test_Batches = [make_batch(s) for s in range(10)]\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Make all the graphs\n",
    "    beta = tf.compat.v1.placeholder(dtype=tf.float32, shape=())\n",
    "    vid_batch = build_video_batch_graph(batch=batch, tmax=tmax, px=px, py=py,pz=pz, r=r, lt=vid_lt)\n",
    "    s_elbo, s_rec, s_pkl, np_elbo, np_rec, np_pkl, \\\n",
    "        p_m,p_v,q_m,q_v,pred_vid, _ = build_sin_and_np_elbo_graphs(vid_batch, beta, lt=model_lt)\n",
    "\n",
    "    # The actual loss functions\n",
    "    if args.elbo==\"SIN\":\n",
    "        loss  = -tf.reduce_mean(s_elbo)\n",
    "        e_elb = tf.reduce_mean(s_elbo)\n",
    "        e_pkl = tf.reduce_mean(s_pkl)\n",
    "        e_rec = tf.reduce_mean(s_rec)\n",
    "    elif args.elbo==\"NP\":\n",
    "        loss  = -tf.reduce_mean(np_elbo)\n",
    "        e_elb = tf.reduce_mean(np_elbo)\n",
    "        e_pkl = tf.reduce_mean(np_pkl)\n",
    "        e_rec = tf.reduce_mean(np_rec)\n",
    "\n",
    "    av_s_elbo = tf.reduce_mean(s_elbo)\n",
    "    av_s_rec  = tf.reduce_mean(s_rec)\n",
    "    av_s_pkl  = tf.reduce_mean(s_pkl)\n",
    "    # Add optimizer ops to graph (minimizing neg elbo!), print out trainable vars\n",
    "    global_step = tf.Variable(0, name='global_step',trainable=False)\n",
    "    optimizer  = tf.compat.v1.train.AdamOptimizer()\n",
    "    train_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "    optim_step = optimizer.minimize(loss=loss, \n",
    "                                    var_list=train_vars,\n",
    "                                    global_step=global_step)\n",
    "    print(\"\\n\\nTrainable variables:\")\n",
    "    for v in train_vars:\n",
    "        print(v)\n",
    "    # Initializer ops for the graph and saver\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    saver = tf.compat.v1.train.Saver()\n",
    "    # Results to be tracked and Pandas saver\n",
    "    res_vars = [global_step,\n",
    "                loss,\n",
    "                av_s_elbo,\n",
    "                av_s_rec,\n",
    "                av_s_pkl,\n",
    "                e_elb,\n",
    "                e_rec,\n",
    "                e_pkl,\n",
    "                tf.math.reduce_min(q_v),\n",
    "                tf.math.reduce_max(q_v),\n",
    "                tf.math.reduce_min(p_v),\n",
    "                tf.math.reduce_max(p_v)]\n",
    "    res_names= [\"Step\",\n",
    "                \"Loss\",\n",
    "                \"Test ELBO\",\n",
    "                \"Test Reconstruction\",\n",
    "                \"Test Prior KL\",\n",
    "                \"Train ELBO\",\n",
    "                \"Train Reconstruction\",\n",
    "                \"Train Prior KL\",\n",
    "                \"min qs_var\",\n",
    "                \"max qs_var\",\n",
    "                \"min q_var\",\n",
    "                \"max q_var\",\n",
    "                \"MSE\",\n",
    "                \"Beta\",\n",
    "                \"Time\"]\n",
    "        # Now let's start doing some computation!\n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=args.ram)\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "\n",
    "        # Attempt to restore weights\n",
    "        try:\n",
    "            saver.restore(sess, tf.train.latest_checkpoint(chkpnt_dir))\n",
    "            print(\"\\n\\nRestored Model Weights\")\n",
    "        except:\n",
    "            sess.run(init_op)\n",
    "            print(\"\\n\\nInitialised Model Weights\")\n",
    "\n",
    "        # Start training that elbo!\n",
    "        for t in range(args.steps):\n",
    "\n",
    "            # Annealing factor for prior KL\n",
    "            beta_t = 1 + (args.beta0-1) * np.exp(t/2000)\n",
    "            # Train: do an optim step\n",
    "            _, g_s = sess.run([optim_step, global_step], {beta:beta_t})\n",
    "            if g_s%20==0:\n",
    "                print(\"ITERATION\", t)\n",
    "                # [[ax_ij.clear() for ax_ij in ax_i] for ax_i in ax]\n",
    "                TT, TD = Test_Batches[0]\n",
    "                reconpath, reconvar, reconvid = sess.run([p_m, p_v, pred_vid], {vid_batch:TD, beta:1})\n",
    "                rp, W, MSE, rv = MSE_rotation(reconpath, TT, reconvar)\n",
    "                k = 8\n",
    "                plot_reconstruction(TD[k:], reconvid[k:], TT[k:], rp[k:], g_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be7b38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
